{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "# from tensorflow.python.keras.layers import Layer # No longer needed, can import from tf.keras\n",
        "from tensorflow.python.keras import backend as K\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "# from tensorflow.python import keras # No longer needed, can use tf.keras directly\n",
        "\n",
        "# Import layers from the standard tf.keras.layers\n",
        "from tensorflow.keras.layers import (\n",
        "    Embedding, Input, Dense, LSTM, GRU, RNN, SimpleRNN, Softmax,\n",
        "    Dropout, Concatenate, TimeDistributed, Layer # Import Layer here\n",
        ")\n",
        "from tensorflow.python.keras.callbacks import Callback\n",
        "from tensorflow.python.keras import Model\n",
        "\n",
        "from math import log\n",
        "import math\n",
        "\n",
        "\n",
        "class AttentionLayer(Layer): # Inherit from the correctly imported Layer\n",
        "    \"\"\"\n",
        "    Implements Bahdanau Attention Mechanism (Additive Attention).\n",
        "    Reference: https://arxiv.org/pdf/1409.0473.pdf\n",
        "\n",
        "    The layer takes as input a sequence of encoder outputs and decoder outputs,\n",
        "    and computes attention weights and context vectors for each decoder timestep.\n",
        "\n",
        "    Trainable weights:\n",
        "        - W_a: applied to encoder outputs\n",
        "        - U_a: applied to decoder state\n",
        "        - V_a: used to produce attention energies\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        super(AttentionLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        \"\"\"\n",
        "        Initialize trainable weights based on input shapes.\n",
        "        input_shape: List of shapes [encoder_output_shape, decoder_output_shape]\n",
        "        \"\"\"\n",
        "        assert isinstance(input_shape, list)\n",
        "\n",
        "        self.W_a = self.add_weight(\n",
        "            name='W_a',\n",
        "            shape=(input_shape[0][2], input_shape[0][2]),\n",
        "            initializer='uniform',\n",
        "            trainable=True\n",
        "        )\n",
        "        self.U_a = self.add_weight(\n",
        "            name='U_a',\n",
        "            shape=(input_shape[1][2], input_shape[0][2]),\n",
        "            initializer='uniform',\n",
        "            trainable=True\n",
        "        )\n",
        "        self.V_a = self.add_weight(\n",
        "            name='V_a',\n",
        "            shape=(input_shape[0][2], 1),\n",
        "            initializer='uniform',\n",
        "            trainable=True\n",
        "        )\n",
        "\n",
        "        super(AttentionLayer, self).build(input_shape)\n",
        "\n",
        "    def call(self, inputs, verbose=False):\n",
        "        \"\"\"\n",
        "        Compute context vectors and attention weights.\n",
        "        Args:\n",
        "            inputs: List of two tensors [encoder_output_seq, decoder_output_seq]\n",
        "            verbose: Flag to print intermediate shapes (for debugging)\n",
        "        Returns:\n",
        "            context_vectors: Weighted sum of encoder outputs per decoder timestep\n",
        "            attention_weights: Attention weights for each encoder timestep\n",
        "        \"\"\"\n",
        "        assert isinstance(inputs, list)\n",
        "        encoder_output_seq, decoder_output_seq = inputs\n",
        "\n",
        "        if verbose:\n",
        "            print('Encoder Output Shape:', encoder_output_seq.shape)\n",
        "            print('Decoder Output Shape:', decoder_output_seq.shape)\n",
        "\n",
        "        def compute_energy(decoder_hidden_state, _):\n",
        "            \"\"\"\n",
        "            Compute attention energy scores for a single decoder timestep.\n",
        "            \"\"\"\n",
        "            # Project encoder outputs using W_a\n",
        "            encoder_projection = K.dot(encoder_output_seq, self.W_a)\n",
        "\n",
        "            # Project current decoder state using U_a and expand dims\n",
        "            decoder_projection = K.expand_dims(K.dot(decoder_hidden_state, self.U_a), 1)\n",
        "\n",
        "            # Compute energy scores with tanh non-linearity and project using V_a\n",
        "            combined_projection = K.tanh(encoder_projection + decoder_projection)\n",
        "            energy_scores = K.squeeze(K.dot(combined_projection, self.V_a), axis=-1)\n",
        "\n",
        "            # Apply softmax to obtain attention weights\n",
        "            attention_weights = K.softmax(energy_scores)\n",
        "\n",
        "            return attention_weights, [attention_weights]\n",
        "\n",
        "        def compute_context(attention_weights, _):\n",
        "            \"\"\"\n",
        "            Compute context vector as the weighted sum of encoder outputs.\n",
        "            \"\"\"\n",
        "            context_vector = K.sum(encoder_output_seq * K.expand_dims(attention_weights, -1), axis=1)\n",
        "            return context_vector, [context_vector]\n",
        "\n",
        "        # Initialize dummy states for RNN functions\n",
        "        # Use tf.zeros_like to create dummy states with correct shapes and dtype\n",
        "        dummy_state_energy = tf.zeros_like(encoder_output_seq[:, 0, :]) # Shape (batch_size, encoder_dim) for energy computation\n",
        "        dummy_state_context = tf.zeros_like(encoder_output_seq[:, 0, :]) # Shape (batch_size, encoder_dim) for context computation\n",
        "\n",
        "\n",
        "        # Run RNN to compute attention weights for all decoder steps\n",
        "        # K.rnn expects initial states with shape (num_states,) + state_shape\n",
        "        # attention_weights_seq is the sequence of outputs\n",
        "        _, attention_weights_seq, _ = K.rnn(\n",
        "            compute_energy, decoder_output_seq, [dummy_state_energy] # Pass dummy state as a list\n",
        "        )\n",
        "\n",
        "        # Run RNN again to compute context vectors using the attention weights\n",
        "        # context_vector_seq is the sequence of outputs\n",
        "        _, context_vector_seq, _ = K.rnn(\n",
        "            compute_context, attention_weights_seq, [dummy_state_context] # Pass dummy state as a list\n",
        "        )\n",
        "\n",
        "        return context_vector_seq, attention_weights_seq\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        \"\"\"\n",
        "        Specify output shapes of the layer.\n",
        "        Returns:\n",
        "            - context_vectors: (batch_size, decoder_timesteps, encoder_dim) - based on the K.sum in compute_context\n",
        "            - attention_weights: (batch_size, decoder_timesteps, encoder_timesteps)\n",
        "        \"\"\"\n",
        "        return [\n",
        "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[0][2])), # Context vector shape should match encoder_dim, not decoder_dim\n",
        "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[0][1]))\n",
        "        ]"
      ],
      "metadata": {
        "id": "WO422P7BGfT0"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For data"
      ],
      "metadata": {
        "id": "32VzzdT4GkOg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4hRsd2_Gj5T",
        "outputId": "aa7ec9d6-c88f-416e-8534-2f438004b563"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = '/content/drive/MyDrive/dakshina_dataset_v1.0/dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.train.tsv'\n",
        "val = '/content/drive/MyDrive/dakshina_dataset_v1.0/dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.dev.tsv'\n",
        "test = '/content/drive/MyDrive/dakshina_dataset_v1.0/dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.test.tsv'"
      ],
      "metadata": {
        "id": "jOhKpzFRGqYE"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing"
      ],
      "metadata": {
        "id": "IZZ9Pu2bI4qn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def training_extract(path):\n",
        "    \"\"\"\n",
        "    Extracts vocabulary and sequence length metadata from a training dataset.\n",
        "\n",
        "    This function reads a tab-separated text file and computes:\n",
        "    - Character-level vocabularies for both input and target sequences.\n",
        "    - Mapping dictionaries between characters and token indices.\n",
        "    - Maximum sequence lengths for encoder and decoder inputs.\n",
        "\n",
        "    Args:\n",
        "        path (str): Path to the training data file.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing:\n",
        "            - num_encoder_tokens (int): Number of unique input characters.\n",
        "            - num_decoder_tokens (int): Number of unique target characters.\n",
        "            - input_token_index (dict): Mapping from input characters to indices.\n",
        "            - target_token_index (dict): Mapping from target characters to indices.\n",
        "            - reverse_input_token_index (dict): Mapping from indices to input characters.\n",
        "            - reverse_target_token_index (dict): Mapping from indices to target characters.\n",
        "            - max_encoder_seq_length (int): Maximum length among all input sequences.\n",
        "            - max_decoder_seq_length (int): Maximum length among all target sequences.\n",
        "    \"\"\"\n",
        "    input_texts = []\n",
        "    target_texts = []\n",
        "    input_characters = set()\n",
        "    target_characters = set()\n",
        "\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as file:\n",
        "        lines = file.read().split(\"\\n\")\n",
        "\n",
        "    for line in lines[:-1]:  # Skip last empty line\n",
        "        target_text, input_text, _ = line.split(\"\\t\")\n",
        "        input_texts.append(input_text)\n",
        "        target_texts.append(\"\\t\" + target_text + \"\\n\")\n",
        "\n",
        "        input_characters.update(input_text)\n",
        "        target_characters.update(target_text)\n",
        "\n",
        "    target_characters.update([\"\\t\", \"\\n\"])\n",
        "\n",
        "    input_characters = sorted(list(input_characters))\n",
        "    target_characters = sorted(list(target_characters))\n",
        "\n",
        "    input_token_index = {char: i for i, char in enumerate(input_characters)}\n",
        "    target_token_index = {char: i for i, char in enumerate(target_characters)}\n",
        "    reverse_input_token_index = {i: char for char, i in input_token_index.items()}\n",
        "    reverse_target_token_index = {i: char for char, i in target_token_index.items()}\n",
        "\n",
        "    num_encoder_tokens = len(input_characters)\n",
        "    num_decoder_tokens = len(target_characters)\n",
        "    max_encoder_seq_length = max(len(txt) for txt in input_texts)\n",
        "    max_decoder_seq_length = max(len(txt) for txt in target_texts)\n",
        "\n",
        "    return (\n",
        "        num_encoder_tokens,\n",
        "        num_decoder_tokens,\n",
        "        input_token_index,\n",
        "        target_token_index,\n",
        "        reverse_input_token_index,\n",
        "        reverse_target_token_index,\n",
        "        max_encoder_seq_length,\n",
        "        max_decoder_seq_length\n",
        "    )\n",
        "\n",
        "\n",
        "def extract_data(path, max_encoder_seq_length, max_decoder_seq_length, num_decoder_tokens):\n",
        "    \"\"\"\n",
        "    Converts raw text data into padded and tokenized input/output arrays for model training.\n",
        "\n",
        "    Each input sequence is converted into a sequence of character indices.\n",
        "    Decoder input and target sequences are prepared in parallel, where\n",
        "    the target is a one-hot encoded representation shifted by one timestep.\n",
        "\n",
        "    Args:\n",
        "        path (str): Path to the input data file.\n",
        "        max_encoder_seq_length (int): Maximum encoder sequence length for padding.\n",
        "        max_decoder_seq_length (int): Maximum decoder sequence length for padding.\n",
        "        num_decoder_tokens (int): Size of the decoder vocabulary.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing:\n",
        "            - input_texts (list): Raw input sequences.\n",
        "            - target_texts (list): Raw target sequences (with start and end tokens).\n",
        "            - encoder_input_data (np.ndarray): Padded token indices for encoder input.\n",
        "            - decoder_input_data (np.ndarray): Padded token indices for decoder input.\n",
        "            - decoder_target_data (np.ndarray): One-hot encoded decoder targets.\n",
        "    \"\"\"\n",
        "    input_texts = []\n",
        "    target_texts = []\n",
        "\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as file:\n",
        "        lines = file.read().split(\"\\n\")\n",
        "\n",
        "    for line in lines[:-1]:  # Skip last empty line\n",
        "        target_text, input_text, _ = line.split(\"\\t\")\n",
        "        input_texts.append(input_text)\n",
        "        target_texts.append(\"\\t\" + target_text + \"\\n\")\n",
        "\n",
        "    encoder_input_data = np.zeros((len(input_texts), max_encoder_seq_length), dtype=\"float32\")\n",
        "    decoder_input_data = np.zeros((len(input_texts), max_decoder_seq_length), dtype=\"float32\")\n",
        "    decoder_target_data = np.zeros((len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\")\n",
        "\n",
        "    for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
        "        for t, char in enumerate(input_text):\n",
        "            encoder_input_data[i, t] = input_token[char]\n",
        "        for t, char in enumerate(target_text):\n",
        "            decoder_input_data[i, t] = target_token[char]\n",
        "            if t > 0:\n",
        "                decoder_target_data[i, t - 1, target_token[char]] = 1.0\n",
        "\n",
        "    return input_texts, target_texts, encoder_input_data, decoder_input_data, decoder_target_data\n"
      ],
      "metadata": {
        "id": "PoGZILliHYJ1"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "tVxDaTnuI7Be"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d=training_extract(train)\n",
        "print(d)\n",
        "num_encoder_tokens =d[0]\n",
        "num_decoder_tokens=d[1]\n",
        "input_token=d[2]\n",
        "target_token=d[3]\n",
        "reverse_input_token=d[4]\n",
        "reverse_target_token=d[5]\n",
        "max_encoder_seq_length=d[6]\n",
        "max_decoder_seq_length=d[7]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BUGG-2LsI-wS",
        "outputId": "cd14e575-99d1-4674-9498-3cd6b3b21e1b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(26, 65, {'a': 0, 'b': 1, 'c': 2, 'd': 3, 'e': 4, 'f': 5, 'g': 6, 'h': 7, 'i': 8, 'j': 9, 'k': 10, 'l': 11, 'm': 12, 'n': 13, 'o': 14, 'p': 15, 'q': 16, 'r': 17, 's': 18, 't': 19, 'u': 20, 'v': 21, 'w': 22, 'x': 23, 'y': 24, 'z': 25}, {'\\t': 0, '\\n': 1, 'ँ': 2, 'ं': 3, 'ः': 4, 'अ': 5, 'आ': 6, 'इ': 7, 'ई': 8, 'उ': 9, 'ऊ': 10, 'ऋ': 11, 'ए': 12, 'ऐ': 13, 'ऑ': 14, 'ओ': 15, 'औ': 16, 'क': 17, 'ख': 18, 'ग': 19, 'घ': 20, 'ङ': 21, 'च': 22, 'छ': 23, 'ज': 24, 'झ': 25, 'ञ': 26, 'ट': 27, 'ठ': 28, 'ड': 29, 'ढ': 30, 'ण': 31, 'त': 32, 'थ': 33, 'द': 34, 'ध': 35, 'न': 36, 'प': 37, 'फ': 38, 'ब': 39, 'भ': 40, 'म': 41, 'य': 42, 'र': 43, 'ल': 44, 'व': 45, 'श': 46, 'ष': 47, 'स': 48, 'ह': 49, '़': 50, 'ा': 51, 'ि': 52, 'ी': 53, 'ु': 54, 'ू': 55, 'ृ': 56, 'ॅ': 57, 'े': 58, 'ै': 59, 'ॉ': 60, 'ो': 61, 'ौ': 62, '्': 63, 'ॐ': 64}, {0: 'a', 1: 'b', 2: 'c', 3: 'd', 4: 'e', 5: 'f', 6: 'g', 7: 'h', 8: 'i', 9: 'j', 10: 'k', 11: 'l', 12: 'm', 13: 'n', 14: 'o', 15: 'p', 16: 'q', 17: 'r', 18: 's', 19: 't', 20: 'u', 21: 'v', 22: 'w', 23: 'x', 24: 'y', 25: 'z'}, {0: '\\t', 1: '\\n', 2: 'ँ', 3: 'ं', 4: 'ः', 5: 'अ', 6: 'आ', 7: 'इ', 8: 'ई', 9: 'उ', 10: 'ऊ', 11: 'ऋ', 12: 'ए', 13: 'ऐ', 14: 'ऑ', 15: 'ओ', 16: 'औ', 17: 'क', 18: 'ख', 19: 'ग', 20: 'घ', 21: 'ङ', 22: 'च', 23: 'छ', 24: 'ज', 25: 'झ', 26: 'ञ', 27: 'ट', 28: 'ठ', 29: 'ड', 30: 'ढ', 31: 'ण', 32: 'त', 33: 'थ', 34: 'द', 35: 'ध', 36: 'न', 37: 'प', 38: 'फ', 39: 'ब', 40: 'भ', 41: 'म', 42: 'य', 43: 'र', 44: 'ल', 45: 'व', 46: 'श', 47: 'ष', 48: 'स', 49: 'ह', 50: '़', 51: 'ा', 52: 'ि', 53: 'ी', 54: 'ु', 55: 'ू', 56: 'ृ', 57: 'ॅ', 58: 'े', 59: 'ै', 60: 'ॉ', 61: 'ो', 62: 'ौ', 63: '्', 64: 'ॐ'}, 20, 21)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract and preprocess training, validation, and test datasets\n",
        "# Each call returns:\n",
        "# - input_texts: raw encoder-side text sequences\n",
        "# - target_texts: raw decoder-side text sequences (with start '\\t' and end '\\n' tokens)\n",
        "# - encoder_input_data: padded and indexed input sequences\n",
        "# - decoder_input_data: padded and indexed decoder input sequences\n",
        "# - decoder_target_data: one-hot encoded shifted decoder output\n",
        "\n",
        "train_input_texts, train_target_texts, encoder_input_train, decoder_input_train, decoder_target_train = extract_data(\n",
        "    train, max_encoder_seq_length, max_decoder_seq_length, num_decoder_tokens)\n",
        "\n",
        "val_input_texts, val_target_texts, encoder_input_val, decoder_input_val, decoder_target_val = extract_data(\n",
        "    val, max_encoder_seq_length, max_decoder_seq_length, num_decoder_tokens)\n",
        "\n",
        "test_input_texts, test_target_texts, encoder_input_test, decoder_input_test, decoder_target_test = extract_data(\n",
        "    test, max_encoder_seq_length, max_decoder_seq_length, num_decoder_tokens)\n",
        "\n",
        "# Print dataset shapes to verify dimensions\n",
        "print(\"Train data shape      :\", encoder_input_train.shape)\n",
        "print(\"Validation data shape :\", encoder_input_val.shape)\n",
        "print(\"Test data shape       :\", encoder_input_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZWEDpdYeI_hS",
        "outputId": "0be0b059-a643-4993-d5c5-50530d1134aa"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data shape      : (44204, 20)\n",
            "Validation data shape : (4358, 20)\n",
            "Test data shape       : (4502, 20)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def beam_search_decoder(prob_distributions, beam_width):\n",
        "    \"\"\"\n",
        "    Performs beam search decoding on a sequence of probability distributions.\n",
        "\n",
        "    Args:\n",
        "        prob_distributions (list of list of float):\n",
        "            A list where each element is a list of probabilities over the vocabulary at that time step.\n",
        "        beam_width (int):\n",
        "            The number of top sequences to keep at each step (beam width).\n",
        "\n",
        "    Returns:\n",
        "        list of list:\n",
        "            Top `beam_width` sequences along with their cumulative log-probability scores.\n",
        "            Each element is a list: [sequence (list of token indices), score (float)]\n",
        "    \"\"\"\n",
        "    # Initialize with an empty sequence and zero score\n",
        "    decoded_sequences = [[[], 0.0]]\n",
        "\n",
        "    # Iterate over each time step's probability distribution\n",
        "    for timestep_probs in prob_distributions:\n",
        "        all_candidates = []\n",
        "\n",
        "        # Expand each sequence in the current beam\n",
        "        for seq, score in decoded_sequences:\n",
        "            for token_idx, token_prob in enumerate(timestep_probs):\n",
        "                new_seq = seq + [token_idx]\n",
        "                new_score = score - log(token_prob)  # Negative log-likelihood\n",
        "                all_candidates.append([new_seq, new_score])\n",
        "\n",
        "        # Keep only the top 'beam_width' sequences\n",
        "        ordered = sorted(all_candidates, key=lambda tup: tup[1])\n",
        "        decoded_sequences = ordered[:beam_width]\n",
        "\n",
        "    return decoded_sequences\n",
        "\n",
        "\n",
        "def translate(token_sequence):\n",
        "    \"\"\"\n",
        "    Converts a sequence of token indices into a string using the reverse target vocabulary.\n",
        "\n",
        "    Args:\n",
        "        token_sequence (list of int):\n",
        "            A list of token indices corresponding to characters.\n",
        "\n",
        "    Returns:\n",
        "        str:\n",
        "            The decoded sentence (string of characters).\n",
        "    \"\"\"\n",
        "    decoded_sentence = [reverse_target_token[idx] for idx in token_sequence]\n",
        "    return \"\".join(decoded_sentence)\n",
        "\n"
      ],
      "metadata": {
        "id": "JfUn4ruHJQL0"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class WordAccuracyCallback(keras.callbacks.Callback):\n",
        "    \"\"\"\n",
        "    Custom Keras Callback to compute word-level accuracy on the validation set\n",
        "    at the end of each epoch using beam search decoding.\n",
        "\n",
        "    Args:\n",
        "        beam_size (int): Number of candidate sequences to consider during beam search.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, beam_size):\n",
        "        super(WordAccuracyCallback, self).__init__()\n",
        "        self.beam_size = beam_size\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        \"\"\"\n",
        "        Called at the end of each epoch. Computes and logs word-level accuracy.\n",
        "        \"\"\"\n",
        "        if logs is None:\n",
        "            logs = {}\n",
        "\n",
        "        # Predict decoder outputs from the model\n",
        "        predictions = self.model.predict([encoder_input_val, decoder_input_val])\n",
        "        correct_predictions = 0\n",
        "\n",
        "        # Iterate through each predicted sample\n",
        "        for i in range(predictions.shape[0]):\n",
        "            # Apply beam search decoding to get top candidate sequences\n",
        "            candidate_sequences = beam_search_decoder(predictions[i], self.beam_size)\n",
        "\n",
        "            # Compare each candidate against the actual target text\n",
        "            for j in range(self.beam_size):\n",
        "                decoded_sequence = translate(candidate_sequences[j][0][:len(val_target_texts[i]) - 1])\n",
        "                if \"\\t\" + decoded_sequence == val_target_texts[i]:\n",
        "                    correct_predictions += 1\n",
        "                    break  # Found a correct candidate, move to next sample\n",
        "\n",
        "        # Calculate and store accuracy (truncated to 4 decimal places)\n",
        "        accuracy = correct_predictions / predictions.shape[0]\n",
        "        logs[\"WordAccuracy\"] = math.trunc(accuracy * 10000) / 10000\n",
        "\n",
        "        print(\"- wordAccuracy:\", logs[\"WordAccuracy\"])\n"
      ],
      "metadata": {
        "id": "9IR2rAUTJlku"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from wandb.integration.keras import WandbMetricsLogger\n",
        "\n",
        "class RNN_Model:\n",
        "    \"\"\"\n",
        "    A customizable RNN-based sequence-to-sequence model with support for\n",
        "    LSTM, GRU, and SimpleRNN cells, attention mechanism, and WordAccuracy tracking.\n",
        "\n",
        "    Parameters:\n",
        "    - embed_size (int): Dimension of the embedding layer.\n",
        "    - no_of_encoder_layers (int): Number of RNN layers in the encoder.\n",
        "    - no_of_decoder_layers (int): Number of RNN layers in the decoder.\n",
        "    - latent_dimension (int): Number of units in each RNN layer.\n",
        "    - dropout (float): Dropout rate for RNN layers.\n",
        "    - recurrent_dropout (float): Recurrent dropout rate.\n",
        "    - cell_type (str): Type of RNN cell to use ('LSTM', 'GRU', or 'RNN').\n",
        "    - beam_size (int): Beam width for beam search during validation.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, embed_size, no_of_encoder_layers, no_of_decoder_layers,\n",
        "                 latent_dimension, dropout, recurrent_dropout, cell_type, beam_size):\n",
        "        self.embed_size = embed_size\n",
        "        self.no_of_encoder_layers = no_of_encoder_layers\n",
        "        self.no_of_decoder_layers = no_of_decoder_layers\n",
        "        self.latent_dimension = latent_dimension\n",
        "        self.dropout = dropout\n",
        "        self.recurrent_dropout = recurrent_dropout\n",
        "        self.cell_type = cell_type\n",
        "        self.beam_size = beam_size\n",
        "\n",
        "        self.model = None\n",
        "        self.input_layers = []    # Encoder layers\n",
        "        self.output_layers = []   # Decoder layers\n",
        "        self.encoder_model = None\n",
        "        self.decoder_model = None\n",
        "\n",
        "    def BUILD_FIT_MODEL(self, en_ip_tr_data, de_ip_tr_data, de_op_tr_data,\n",
        "                        epochs, batch_size, max_encoder_seq_length, num_encoder_tokens,\n",
        "                        max_decoder_seq_length, num_decoder_tokens):\n",
        "        \"\"\"\n",
        "        Builds and trains the encoder-decoder model with attention.\n",
        "\n",
        "        Args:\n",
        "            en_ip_tr_data (ndarray): Encoder input training data.\n",
        "            de_ip_tr_data (ndarray): Decoder input training data.\n",
        "            de_op_tr_data (ndarray): Decoder output training data (one-hot).\n",
        "            epochs (int): Number of training epochs.\n",
        "            batch_size (int): Batch size for training.\n",
        "            max_encoder_seq_length (int): Max length of encoder input sequences.\n",
        "            num_encoder_tokens (int): Size of encoder vocabulary.\n",
        "            max_decoder_seq_length (int): Max length of decoder input sequences.\n",
        "            num_decoder_tokens (int): Size of decoder vocabulary.\n",
        "        \"\"\"\n",
        "\n",
        "        # Encoder\n",
        "        encoder_inputs = Input(shape=(max_encoder_seq_length,))\n",
        "        x = Embedding(input_dim=num_encoder_tokens,\n",
        "                      output_dim=self.embed_size,\n",
        "                      input_length=max_encoder_seq_length,\n",
        "                      name='enc_embd_layer')(encoder_inputs)\n",
        "\n",
        "        encoder_states = []\n",
        "\n",
        "        for _ in range(self.no_of_encoder_layers):\n",
        "            if self.cell_type == 'LSTM':\n",
        "                rnn = LSTM(self.latent_dimension, return_sequences=True,\n",
        "                           return_state=True, dropout=self.dropout,\n",
        "                           recurrent_dropout=self.recurrent_dropout)\n",
        "            elif self.cell_type == 'GRU':\n",
        "                rnn = GRU(self.latent_dimension, return_sequences=True,\n",
        "                          return_state=True, dropout=self.dropout,\n",
        "                          recurrent_dropout=self.recurrent_dropout)\n",
        "            elif self.cell_type == 'RNN':\n",
        "                rnn = SimpleRNN(self.latent_dimension, return_sequences=True,\n",
        "                                return_state=True, dropout=self.dropout,\n",
        "                                recurrent_dropout=self.recurrent_dropout)\n",
        "            self.input_layers.append(rnn)\n",
        "            outputs = rnn(x)\n",
        "            x, states = outputs[0], outputs[1:]\n",
        "            encoder_states.append(states)\n",
        "\n",
        "        encoder_outputs = x\n",
        "\n",
        "        # Decoder\n",
        "        decoder_inputs = Input(shape=(max_decoder_seq_length,))\n",
        "        y = Embedding(input_dim=num_decoder_tokens,\n",
        "                      output_dim=self.embed_size,\n",
        "                      input_length=max_decoder_seq_length,\n",
        "                      name='dec_embd_layer')(decoder_inputs)\n",
        "\n",
        "        for i in range(self.no_of_decoder_layers):\n",
        "            initial_state = encoder_states[i]\n",
        "            rnn = None\n",
        "            if self.cell_type == 'LSTM':\n",
        "                rnn = LSTM(self.latent_dimension, return_sequences=True,\n",
        "                           return_state=True, dropout=self.dropout,\n",
        "                           recurrent_dropout=self.recurrent_dropout)\n",
        "            elif self.cell_type == 'GRU':\n",
        "                rnn = GRU(self.latent_dimension, return_sequences=True,\n",
        "                          return_state=True, dropout=self.dropout,\n",
        "                          recurrent_dropout=self.recurrent_dropout)\n",
        "            elif self.cell_type == 'RNN':\n",
        "                rnn = SimpleRNN(self.latent_dimension, return_sequences=True,\n",
        "                                return_state=True, dropout=self.dropout,\n",
        "                                recurrent_dropout=self.recurrent_dropout)\n",
        "            self.output_layers.append(rnn)\n",
        "            y, _ = rnn(y, initial_state=initial_state)\n",
        "\n",
        "        decoder_outputs = y\n",
        "\n",
        "        # Attention Layer\n",
        "        attn_layer = AttentionLayer(name='attention_layer')\n",
        "        attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n",
        "\n",
        "        # Concatenate attention output with decoder RNN output\n",
        "        decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
        "\n",
        "        # Output Dense Layer\n",
        "        dense = Dense(num_decoder_tokens, activation='softmax', name='dense_layer')\n",
        "        decoder_pred = TimeDistributed(dense, name='time_distributed_layer')(decoder_concat_input)\n",
        "\n",
        "        # Final model\n",
        "        self.model = keras.Model([encoder_inputs, decoder_inputs], decoder_pred)\n",
        "        self.model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "        # Train the model\n",
        "        self.model.fit(\n",
        "            [en_ip_tr_data, de_ip_tr_data],\n",
        "            de_op_tr_data,\n",
        "            batch_size=batch_size,\n",
        "            epochs=epochs,\n",
        "            shuffle=True,\n",
        "            callbacks=[\n",
        "                WordAccuracyCallback(self.beam_size),\n",
        "                WandbMetricsLogger(log_freq=\"epoch\")\n",
        "            ],\n",
        "            verbose=1\n",
        "        )\n"
      ],
      "metadata": {
        "id": "u7KYtBHQLnPA"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb\n",
        "import wandb\n",
        "wandb.login()"
      ],
      "metadata": {
        "id": "7ZYUeIGrhmwn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39fa91bb-21ec-411e-a59b-6e767d887898"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.19.11)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.2.0)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.8)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.29.4)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.11.4)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.28.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb) (1.3.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb) (75.2.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.13.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2025.4.26)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sweep Configuration"
      ],
      "metadata": {
        "id": "61NGXI9DNdtJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sweep_config = {\n",
        "  'name': 'RNN',\n",
        "  'method': 'bayes',\n",
        "  'metric': {\n",
        "      'name': 'accuracy',\n",
        "      'goal': 'maximize'\n",
        "    },\n",
        "\n",
        "  'early_terminate': {\n",
        "        'type': 'hyperband',\n",
        "        'min_iter': 3,\n",
        "        'max_iter': 20,\n",
        "        's': 2\n",
        "    },\n",
        "\n",
        "  'parameters': {\n",
        "        'epochs':{\n",
        "            'values':[10, 20, 30]\n",
        "        },\n",
        "        'batch_size':{\n",
        "            'values':[32, 64, 128]\n",
        "        },\n",
        "        'encoder_layers':{\n",
        "            'values':[1, 2, 3]\n",
        "        },\n",
        "        'decoder_layers':{\n",
        "            'values':[1, 2, 3]\n",
        "        },\n",
        "        'hidden_layer_size':{\n",
        "            'values':[16, 32, 64, 256]\n",
        "        },\n",
        "        'cell_type':{\n",
        "            'values':['GRU', 'LSTM','RNN']\n",
        "        },\n",
        "        'dropout':{\n",
        "            'values':[0, 0.2, 0.3]\n",
        "        },\n",
        "        'recurrent_dropout':{\n",
        "            'values':[0, 0.2, 0.3]\n",
        "        },\n",
        "        'beam_size':{\n",
        "            'values':[1, 3, 5]\n",
        "        }\n",
        "\n",
        "    }\n",
        "\n",
        "}\n",
        "\n"
      ],
      "metadata": {
        "id": "JugLyPgnhquG"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sweep_id = wandb.sweep(sweep_config, project = 'DL_Assignment3 with attention', entity = 'me21b118-iit-madras' )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmb24t82Nhy1",
        "outputId": "eff85653-06d1-4d4a-8bee-8e7f08761f82"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create sweep with ID: 9ybcvf5q\n",
            "Sweep URL: https://wandb.ai/me21b118-iit-madras/DL_Assignment3%20with%20attention/sweeps/9ybcvf5q\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train():\n",
        "    \"\"\"\n",
        "    Trains the RNN model with attention using parameters from a WandB run.\n",
        "\n",
        "    This function is designed to be the target function for a WandB sweep.\n",
        "    It initializes a new WandB run, configures the model based on the run's\n",
        "    hyperparameters, builds and trains the model using the preprocessed data,\n",
        "    and logs metrics to WandB via the WandbMetricsLogger callback.\n",
        "    \"\"\"\n",
        "    # Start a new WandB run\n",
        "    run = wandb.init()\n",
        "\n",
        "    # Get hyperparameters from the WandB run configuration\n",
        "    config = run.config\n",
        "\n",
        "    # Initialize the RNN_Model with hyperparameters from the run config\n",
        "    rnn_model_with_attention = RNN_Model(\n",
        "        embed_size=config.hidden_layer_size,  # Using hidden_layer_size for embedding size\n",
        "        no_of_encoder_layers=config.encoder_layers,\n",
        "        no_of_decoder_layers=config.decoder_layers,\n",
        "        latent_dimension=config.hidden_layer_size,\n",
        "        dropout=config.dropout,\n",
        "        recurrent_dropout=config.recurrent_dropout,\n",
        "        cell_type=config.cell_type,\n",
        "        beam_size=config.beam_size\n",
        "    )\n",
        "\n",
        "    # Build and train the model\n",
        "    rnn_model_with_attention.BUILD_FIT_MODEL(\n",
        "        encoder_input_train,\n",
        "        decoder_input_train,\n",
        "        decoder_target_train,\n",
        "        epochs=config.epochs,\n",
        "        batch_size=config.batch_size,\n",
        "        max_encoder_seq_length=max_encoder_seq_length,\n",
        "        num_encoder_tokens=num_encoder_tokens,\n",
        "        max_decoder_seq_length=max_decoder_seq_length,\n",
        "        num_decoder_tokens=num_decoder_tokens\n",
        "    )\n",
        "\n",
        "    # Finish the WandB run\n",
        "    run.finish()\n"
      ],
      "metadata": {
        "id": "Eq9dgTZ1O24G"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Kick off the sweep agent\n",
        "wandb.agent(sweep_id=sweep_id, function=train, count=7)"
      ],
      "metadata": {
        "id": "mtfSYur3Pf32"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}